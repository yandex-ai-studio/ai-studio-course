{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function Calling: –ê–≥–µ–Ω—Ç-–∏—Å—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å –Ω–∞—É—á–Ω—ã—Ö —Å—Ç–∞—Ç–µ–π\n",
    "\n",
    "–í —ç—Ç–æ–º –Ω–æ—É—Ç–±—É–∫–µ –º—ã —Å–æ–∑–¥–∞–¥–∏–º –∞–≥–µ–Ω—Ç–∞, –∫–æ—Ç–æ—Ä—ã–π —É–º–µ–µ—Ç –∏—Å–∫–∞—Ç—å –Ω–∞—É—á–Ω—ã–µ —Å—Ç–∞—Ç—å–∏ –Ω–∞ **arXiv** ‚Äî –∫—Ä—É–ø–Ω–µ–π—à–µ–º –æ—Ç–∫—Ä—ã—Ç–æ–º —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–∏ –ø—Ä–µ–ø—Ä–∏–Ω—Ç–æ–≤.\n",
    "\n",
    "## –ó–∞–¥–∞—á–∞\n",
    "\n",
    "–ê–≥–µ–Ω—Ç –±—É–¥–µ—Ç:\n",
    "1. –ü–æ–ª—É—á–∞—Ç—å —Ç–µ–º—É –¥–ª—è –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è –æ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è\n",
    "2. –ò—Å–∫–∞—Ç—å —Å—Ç–∞—Ç—å–∏ –Ω–∞ arXiv —á–µ—Ä–µ–∑ API\n",
    "3. –ê–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∏ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è—Ç—å –∫—Ä–∞—Ç–∫–æ–µ —Ä–µ–∑—é–º–µ\n",
    "\n",
    "–ù–∞—á–Ω—ë–º —Å —É—Å—Ç–∞–Ω–æ–≤–∫–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã—Ö –±–∏–±–ª–∏–æ—Ç–µ–∫:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install --upgrade openai python-dotenv feedparser requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**–í–ù–ò–ú–ê–ù–ò–ï**: –ü–æ—Å–ª–µ —É—Å—Ç–∞–Ω–æ–≤–∫–∏ –±–∏–±–ª–∏–æ—Ç–µ–∫ —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –ø–µ—Ä–µ–∑–∞–ø—É—Å—Ç–∏—Ç—å Kernel –Ω–æ—É—Ç–±—É–∫–∞."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl -o .env {{url_of_dotenv_file}}\\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ –ê–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏—è –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∞ (folder_id: b1gst3c7...)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "folder_id = os.environ[\"folder_id\"]\n",
    "api_key = os.environ[\"api_key\"]\n",
    "\n",
    "def printx(string):\n",
    "    display(Markdown(string))\n",
    "\n",
    "print(f\"‚úÖ –ê–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏—è –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∞ (folder_id: {folder_id[:8]}...)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## –ß–∞—Å—Ç—å 1: –ó–Ω–∞–∫–æ–º—Å—Ç–≤–æ —Å arXiv API\n",
    "\n",
    "arXiv –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è–µ—Ç –±–µ—Å–ø–ª–∞—Ç–Ω—ã–π API –¥–ª—è –ø–æ–∏—Å–∫–∞ –∏ –ø–æ–ª—É—á–µ–Ω–∏—è –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö —Å—Ç–∞—Ç–µ–π. API –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –≤ —Ñ–æ—Ä–º–∞—Ç–µ Atom (XML), –∫–æ—Ç–æ—Ä—ã–π —É–¥–æ–±–Ω–æ –ø–∞—Ä—Å–∏—Ç—å —Å –ø–æ–º–æ—â—å—é –±–∏–±–ª–∏–æ—Ç–µ–∫–∏ `feedparser`.\n",
    "\n",
    "### –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –∑–∞–ø—Ä–æ—Å–∞\n",
    "\n",
    "```\n",
    "http://export.arxiv.org/api/query?search_query={query}&start=0&max_results=10\n",
    "```\n",
    "\n",
    "### –ü–æ–ª—è –¥–ª—è –ø–æ–∏—Å–∫–∞:\n",
    "- `ti:` ‚Äî –∑–∞–≥–æ–ª–æ–≤–æ–∫ (title)\n",
    "- `au:` ‚Äî –∞–≤—Ç–æ—Ä (author)\n",
    "- `abs:` ‚Äî –∞–Ω–Ω–æ—Ç–∞—Ü–∏—è (abstract)\n",
    "- `all:` ‚Äî –≤—Å–µ –ø–æ–ª—è\n",
    "\n",
    "–ú–æ–∂–Ω–æ –∫–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞—Ç—å —Å –æ–ø–µ—Ä–∞—Ç–æ—Ä–∞–º–∏: `AND`, `OR`, `ANDNOT`\n",
    "\n",
    "–î–∞–≤–∞–π—Ç–µ –ø–æ–ø—Ä–æ–±—É–µ–º –ø—Ä–æ—Å—Ç–æ–π –∑–∞–ø—Ä–æ—Å:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "URL –∑–∞–ø—Ä–æ—Å–∞: http://export.arxiv.org/api/query?...\n",
      "\n",
      "–ù–∞–π–¥–µ–Ω–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤: 15134\n",
      "\n",
      "--- –°—Ç–∞—Ç—å—è 1 ---\n",
      "–ó–∞–≥–æ–ª–æ–≤–æ–∫: Dilated Neighborhood Attention Transformer\n",
      "–ê–≤—Ç–æ—Ä—ã: Ali Hassani, Humphrey Shi\n",
      "arXiv ID: 2209.15001v3\n",
      "–ö–∞—Ç–µ–≥–æ—Ä–∏–∏: cs.CV, cs.AI, cs.LG\n",
      "–ê–Ω–Ω–æ—Ç–∞—Ü–∏—è: Transformers are quickly becoming one of the most heavily applied deep learning architectures across modalities, domains, and tasks. In vision, on top of ongoing efforts into plain transformers, hiera...\n",
      "\n",
      "--- –°—Ç–∞—Ç—å—è 2 ---\n",
      "–ó–∞–≥–æ–ª–æ–≤–æ–∫: Transformer-based Personalized Attention Mechanism for Medical Images with Clinical Records\n",
      "–ê–≤—Ç–æ—Ä—ã: Yusuke Takagi, Noriaki Hashimoto, Hiroki Masuda, Hiroaki Miyoshi, Koichi Ohshima, Hidekata Hontani, Ichiro Takeuchi\n",
      "arXiv ID: 2206.03003v2\n",
      "–ö–∞—Ç–µ–≥–æ—Ä–∏–∏: eess.IV, cs.CV\n",
      "–ê–Ω–Ω–æ—Ç–∞—Ü–∏—è: In medical image diagnosis, identifying the attention region, i.e., the region of interest for which the diagnosis is made, is an important task. Various methods have been developed to automatically i...\n",
      "\n",
      "--- –°—Ç–∞—Ç—å—è 3 ---\n",
      "–ó–∞–≥–æ–ª–æ–≤–æ–∫: Vision Transformer with Quadrangle Attention\n",
      "–ê–≤—Ç–æ—Ä—ã: Qiming Zhang, Jing Zhang, Yufei Xu, Dacheng Tao\n",
      "arXiv ID: 2303.15105v1\n",
      "–ö–∞—Ç–µ–≥–æ—Ä–∏–∏: cs.CV\n",
      "–ê–Ω–Ω–æ—Ç–∞—Ü–∏—è: Window-based attention has become a popular choice in vision transformers due to its superior performance, lower computational complexity, and less memory footprint. However, the design of hand-crafte...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import feedparser\n",
    "\n",
    "# –ë–∞–∑–æ–≤—ã–π URL –¥–ª—è API\n",
    "ARXIV_API_URL = \"http://export.arxiv.org/api/query\"\n",
    "\n",
    "# –ü–æ–∏—Å–∫–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å: —Å—Ç–∞—Ç—å–∏ –ø—Ä–æ —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä—ã –≤ –º–∞—à–∏–Ω–Ω–æ–º –æ–±—É—á–µ–Ω–∏–∏\n",
    "search_query = \"all:transformer+AND+attention\"\n",
    "max_results = 3\n",
    "\n",
    "# –§–æ—Ä–º–∏—Ä—É–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –∑–∞–ø—Ä–æ—Å–∞\n",
    "params = {\"search_query\": search_query, \"start\": 0, \"max_results\": max_results}\n",
    "print(f\"URL –∑–∞–ø—Ä–æ—Å–∞: {ARXIV_API_URL}?...\\n\")\n",
    "\n",
    "# –í—ã–ø–æ–ª–Ω—è–µ–º –∑–∞–ø—Ä–æ—Å\n",
    "response = requests.get(ARXIV_API_URL, params=params)\n",
    "feed = feedparser.parse(response.content)\n",
    "\n",
    "# –í—ã–≤–æ–¥–∏–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã\n",
    "print(f\"–ù–∞–π–¥–µ–Ω–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤: {feed.feed.opensearch_totalresults}\\n\")\n",
    "\n",
    "for i, entry in enumerate(feed.entries, 1):\n",
    "    print(f\"--- –°—Ç–∞—Ç—å—è {i} ---\")\n",
    "    print(f\"–ó–∞–≥–æ–ª–æ–≤–æ–∫: {entry.title}\")\n",
    "    print(f\"–ê–≤—Ç–æ—Ä—ã: {', '.join(a.name for a in entry.authors)}\")\n",
    "    print(f\"arXiv ID: {entry.id.split('/abs/')[-1]}\")\n",
    "    print(f\"–ö–∞—Ç–µ–≥–æ—Ä–∏–∏: {', '.join(t['term'] for t in entry.tags)}\")\n",
    "    print(f\"–ê–Ω–Ω–æ—Ç–∞—Ü–∏—è: {entry.summary[:200]}...\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## –ß–∞—Å—Ç—å 2: –ù–∞—Å—Ç—Ä–æ–π–∫–∞ OpenAI –∫–ª–∏–µ–Ω—Ç–∞\n",
    "\n",
    "–°–æ–∑–¥–∞–¥–∏–º –∫–ª–∏–µ–Ω—Ç –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å Yandex Cloud —á–µ—Ä–µ–∑ OpenAI-—Å–æ–≤–º–µ—Å—Ç–∏–º—ã–π API:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ –ö–ª–∏–µ–Ω—Ç OpenAI –Ω–∞—Å—Ç—Ä–æ–µ–Ω\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "model = f\"gpt://{folder_id}/qwen3-235b-a22b-fp8/latest\"\n",
    "\n",
    "client = OpenAI(\n",
    "    base_url=\"https://ai.api.cloud.yandex.net/v1\",\n",
    "    api_key=api_key,\n",
    "    project=folder_id\n",
    ")\n",
    "\n",
    "print(\"‚úÖ –ö–ª–∏–µ–Ω—Ç OpenAI –Ω–∞—Å—Ç—Ä–æ–µ–Ω\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## –ß–∞—Å—Ç—å 3: –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ñ—É–Ω–∫—Ü–∏–π –¥–ª—è Function Calling\n",
    "\n",
    "–°–æ–∑–¥–∞–¥–∏–º –¥–≤–µ —Ñ—É–Ω–∫—Ü–∏–∏:\n",
    "1. **search_arxiv** ‚Äî –ø–æ–∏—Å–∫ —Å—Ç–∞—Ç–µ–π –ø–æ –∑–∞–ø—Ä–æ—Å—É\n",
    "2. **get_paper_details** ‚Äî –ø–æ–ª—É—á–µ–Ω–∏–µ –ø–æ–¥—Ä–æ–±–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ —Å—Ç–∞—Ç—å–µ –ø–æ ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ –û–ø—Ä–µ–¥–µ–ª–µ–Ω–æ 2 —Ñ—É–Ω–∫—Ü–∏–π –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å arXiv\n"
     ]
    }
   ],
   "source": [
    "# –û–ø–∏—Å–∞–Ω–∏–µ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤ –¥–ª—è Function Calling\n",
    "arxiv_tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"name\": \"search_arxiv\",\n",
    "        \"description\": \"–ü–æ–∏—Å–∫ –Ω–∞—É—á–Ω—ã—Ö —Å—Ç–∞—Ç–µ–π –Ω–∞ arXiv –ø–æ –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–∞–º. –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ç–æ–ø-3 –Ω–∞–∏–±–æ–ª–µ–µ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö —Å—Ç–∞—Ç—å–∏.\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"query\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"–ü–æ–∏—Å–∫–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å –Ω–∞ –∞–Ω–≥–ª–∏–π—Å–∫–æ–º —è–∑—ã–∫–µ. –ú–æ–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ —á–µ—Ä–µ–∑ –ø—Ä–æ–±–µ–ª.\"\n",
    "                },\n",
    "                \"field\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"enum\": [\"all\", \"title\", \"abstract\", \"author\"],\n",
    "                    \"description\": \"–ü–æ–ª–µ –¥–ª—è –ø–æ–∏—Å–∫–∞: all (–≤—Å–µ –ø–æ–ª—è), title (–∑–∞–≥–æ–ª–æ–≤–æ–∫), abstract (–∞–Ω–Ω–æ—Ç–∞—Ü–∏—è), author (–∞–≤—Ç–æ—Ä)\"\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"query\"]\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"name\": \"get_paper_details\",\n",
    "        \"description\": \"–ü–æ–ª—É—á–∏—Ç—å –ø–æ–ª–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Å—Ç–∞—Ç—å–µ –ø–æ –µ—ë arXiv ID, –≤–∫–ª—é—á–∞—è –ø–æ–ª–Ω—É—é –∞–Ω–Ω–æ—Ç–∞—Ü–∏—é.\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"arxiv_id\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"–ò–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä —Å—Ç–∞—Ç—å–∏ –Ω–∞ arXiv (–Ω–∞–ø—Ä–∏–º–µ—Ä, 2304.12345 –∏–ª–∏ 2304.12345v1)\"\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"arxiv_id\"]\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "print(f\"‚úÖ –û–ø—Ä–µ–¥–µ–ª–µ–Ω–æ {len(arxiv_tools)} —Ñ—É–Ω–∫—Ü–∏–π –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å arXiv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## –ß–∞—Å—Ç—å 4: –†–µ–∞–ª–∏–∑–∞—Ü–∏—è —Ñ—É–Ω–∫—Ü–∏–π\n",
    "\n",
    "–¢–µ–ø–µ—Ä—å —Ä–µ–∞–ª–∏–∑—É–µ–º —Å–∞–º–∏ —Ñ—É–Ω–∫—Ü–∏–∏, –∫–æ—Ç–æ—Ä—ã–µ –±—É–¥—É—Ç –≤—ã–ø–æ–ª–Ω—è—Ç—å –∑–∞–ø—Ä–æ—Å—ã –∫ arXiv API:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== –¢–µ—Å—Ç search_arxiv ===\n",
      "–ù–∞–π–¥–µ–Ω–æ —Å—Ç–∞—Ç–µ–π: 17323. –¢–æ–ø-3:\n",
      "\n",
      "1. **Large Language Models are Biased Because They Are Large Language Models**\n",
      "   - arXiv ID: 2406.13138v2\n",
      "   - –ê–≤—Ç–æ—Ä—ã: Philip Resnik\n",
      "   - –ê–Ω–Ω–æ—Ç–∞—Ü–∏—è: This position paper's primary goal is to provoke thoughtful discussion about the relationship between bias and fundamental properties of large language models. I do this by seeking to convince the reader that harmful biases are an inevitable consequence arising from the design of any large language ...\n",
      "\n",
      "2. **Large Language Models**\n",
      "   - arXiv ID: 2307.05782v2\n",
      "   - –ê–≤—Ç–æ—Ä—ã: Michael R. Douglas\n",
      "   - –ê–Ω–Ω–æ—Ç–∞—Ü–∏—è: Artificial intelligence is making spectacular progress, and one of the best examples is the development of large language models (LLMs) such as OpenAI's GPT series. In these lectures, written for readers with a background in mathematics or physics, we give a brief history and survey of the state of ...\n",
      "\n",
      "3. **On the Thinking-Language Modeling Gap in Large Language Models**\n",
      "   - arXiv ID: 2505.12896v1\n",
      "   - –ê–≤—Ç–æ—Ä—ã: Chenxi Liu, Yongqiang Chen, Tongliang Liu –∏ –¥—Ä.\n",
      "   - –ê–Ω–Ω–æ—Ç–∞—Ü–∏—è: System 2 reasoning is one of the defining characteristics of intelligence, which requires slow and logical thinking. Human conducts System 2 reasoning via the language of thoughts that organizes the reasoning process as a causal sequence of mental language, or thoughts. Recently, it has been observe...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import feedparser\n",
    "\n",
    "ARXIV_API_URL = \"http://export.arxiv.org/api/query\"\n",
    "\n",
    "# –ú–∞–ø–ø–∏–Ω–≥ –ø–æ–ª–µ–π\n",
    "FIELD_MAP = {\n",
    "    \"all\": \"all\",\n",
    "    \"title\": \"ti\",\n",
    "    \"abstract\": \"abs\",\n",
    "    \"author\": \"au\"\n",
    "}\n",
    "\n",
    "\n",
    "def search_arxiv(query: str, field: str = \"all\", max_results: int = 3) -> str:\n",
    "    \"\"\"\n",
    "    –ü–æ–∏—Å–∫ —Å—Ç–∞—Ç–µ–π –Ω–∞ arXiv.\n",
    "    \n",
    "    Args:\n",
    "        query: –ü–æ–∏—Å–∫–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å\n",
    "        field: –ü–æ–ª–µ –¥–ª—è –ø–æ–∏—Å–∫–∞ (all, title, abstract, author)\n",
    "        max_results: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ —á–∏—Å–ª–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤\n",
    "    \n",
    "    Returns:\n",
    "        –°—Ç—Ä–æ–∫–∞ —Å –æ–ø–∏—Å–∞–Ω–∏–µ–º –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö —Å—Ç–∞—Ç–µ–π\n",
    "    \"\"\"\n",
    "    # –§–æ—Ä–º–∏—Ä—É–µ–º –ø–æ–∏—Å–∫–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å\n",
    "    field_prefix = FIELD_MAP.get(field, \"all\")\n",
    "    \n",
    "    # –ó–∞–º–µ–Ω—è–µ–º –ø—Ä–æ–±–µ–ª—ã –Ω–∞ +\n",
    "    query_formatted = query.replace(\" \", \"+\")\n",
    "    search_query = f\"{field_prefix}:{query_formatted}\"\n",
    "    \n",
    "    # –§–æ—Ä–º–∏—Ä—É–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –∑–∞–ø—Ä–æ—Å–∞\n",
    "    params = {\n",
    "        \"search_query\": search_query,\n",
    "        \"start\": 0,\n",
    "        \"max_results\": max_results,\n",
    "        \"sortBy\": \"relevance\",\n",
    "        \"sortOrder\": \"descending\"\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(ARXIV_API_URL, params=params, timeout=10)\n",
    "        feed = feedparser.parse(response.content)\n",
    "        \n",
    "        if not feed.entries:\n",
    "            return \"–°—Ç–∞—Ç—å–∏ –ø–æ –¥–∞–Ω–Ω–æ–º—É –∑–∞–ø—Ä–æ—Å—É –Ω–µ –Ω–∞–π–¥–µ–Ω—ã.\"\n",
    "        \n",
    "        results = []\n",
    "        for i, entry in enumerate(feed.entries, 1):\n",
    "            arxiv_id = entry.id.split('/abs/')[-1]\n",
    "            authors = ', '.join(a.name for a in entry.authors[:3])\n",
    "            if len(entry.authors) > 3:\n",
    "                authors += \" –∏ –¥—Ä.\"\n",
    "            \n",
    "            # –£–∫–æ—Ä–∞—á–∏–≤–∞–µ–º –∞–Ω–Ω–æ—Ç–∞—Ü–∏—é\n",
    "            summary = entry.summary.replace('\\n', ' ')[:300]\n",
    "            \n",
    "            results.append(\n",
    "                f\"{i}. **{entry.title}**\\n\"\n",
    "                f\"   - arXiv ID: {arxiv_id}\\n\"\n",
    "                f\"   - –ê–≤—Ç–æ—Ä—ã: {authors}\\n\"\n",
    "                f\"   - –ê–Ω–Ω–æ—Ç–∞—Ü–∏—è: {summary}...\\n\"\n",
    "            )\n",
    "        \n",
    "        return f\"–ù–∞–π–¥–µ–Ω–æ —Å—Ç–∞—Ç–µ–π: {feed.feed.opensearch_totalresults}. –¢–æ–ø-{max_results}:\\n\\n\" + \"\\n\".join(results)\n",
    "    \n",
    "    except Exception as e:\n",
    "        return f\"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–ø—Ä–æ—Å–µ –∫ arXiv: {str(e)}\"\n",
    "\n",
    "\n",
    "def get_paper_details(arxiv_id: str) -> str:\n",
    "    \"\"\"\n",
    "    –ü–æ–ª—É—á–∏—Ç—å –ø–æ–¥—Ä–æ–±–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Å—Ç–∞—Ç—å–µ –ø–æ arXiv ID.\n",
    "    \n",
    "    Args:\n",
    "        arxiv_id: –ò–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä —Å—Ç–∞—Ç—å–∏\n",
    "    \n",
    "    Returns:\n",
    "        –°—Ç—Ä–æ–∫–∞ —Å –ø–æ–ª–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π –æ —Å—Ç–∞—Ç—å–µ\n",
    "    \"\"\"\n",
    "    # –û—á–∏—â–∞–µ–º ID –æ—Ç –≤–æ–∑–º–æ–∂–Ω—ã—Ö –ø—Ä–µ—Ñ–∏–∫—Å–æ–≤\n",
    "    arxiv_id = arxiv_id.replace(\"arXiv:\", \"\").strip()\n",
    "    \n",
    "    params = {\n",
    "        \"id_list\": arxiv_id,\n",
    "        \"max_results\": 1\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(ARXIV_API_URL, params=params, timeout=10)\n",
    "        feed = feedparser.parse(response.content)\n",
    "        \n",
    "        if not feed.entries:\n",
    "            return f\"–°—Ç–∞—Ç—å—è —Å ID {arxiv_id} –Ω–µ –Ω–∞–π–¥–µ–Ω–∞.\"\n",
    "        \n",
    "        entry = feed.entries[0]\n",
    "        authors = ', '.join(a.name for a in entry.authors)\n",
    "        categories = ', '.join(t['term'] for t in entry.tags)\n",
    "        \n",
    "        # –ü–æ–ª—É—á–∞–µ–º —Å—Å—ã–ª–∫–∏\n",
    "        pdf_link = \"\"\n",
    "        abs_link = \"\"\n",
    "        for link in entry.links:\n",
    "            if link.get('title') == 'pdf':\n",
    "                pdf_link = link.href\n",
    "            if link.rel == 'alternate':\n",
    "                abs_link = link.href\n",
    "        \n",
    "        result = (\n",
    "            f\"**{entry.title}**\\n\\n\"\n",
    "            f\"**arXiv ID:** {arxiv_id}\\n\"\n",
    "            f\"**–ê–≤—Ç–æ—Ä—ã:** {authors}\\n\"\n",
    "            f\"**–û–ø—É–±–ª–∏–∫–æ–≤–∞–Ω–æ:** {entry.published}\\n\"\n",
    "            f\"**–ö–∞—Ç–µ–≥–æ—Ä–∏–∏:** {categories}\\n\"\n",
    "            f\"**–°—Å—ã–ª–∫–∞ –Ω–∞ —Å—Ç–∞—Ç—å—é:** {abs_link}\\n\"\n",
    "            f\"**–°—Å—ã–ª–∫–∞ –Ω–∞ PDF:** {pdf_link}\\n\\n\"\n",
    "            f\"**–ê–Ω–Ω–æ—Ç–∞—Ü–∏—è:**\\n{entry.summary}\"\n",
    "        )\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    except Exception as e:\n",
    "        return f\"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–ø—Ä–æ—Å–µ –∫ arXiv: {str(e)}\"\n",
    "\n",
    "\n",
    "# –¢–µ—Å—Ç–∏—Ä—É–µ–º —Ñ—É–Ω–∫—Ü–∏–∏\n",
    "print(\"=== –¢–µ—Å—Ç search_arxiv ===\")\n",
    "print(search_arxiv(\"large language models\", \"title\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== –¢–µ—Å—Ç get_paper_details ===\n",
      "**Attention Is All You Need**\n",
      "\n",
      "**arXiv ID:** 1706.03762\n",
      "**–ê–≤—Ç–æ—Ä—ã:** Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser, Illia Polosukhin\n",
      "**–û–ø—É–±–ª–∏–∫–æ–≤–∞–Ω–æ:** 2017-06-12T17:57:34Z\n",
      "**–ö–∞—Ç–µ–≥–æ—Ä–∏–∏:** cs.CL, cs.LG\n",
      "**–°—Å—ã–ª–∫–∞ –Ω–∞ —Å—Ç–∞—Ç—å—é:** https://arxiv.org/abs/1706.03762v7\n",
      "**–°—Å—ã–ª–∫–∞ –Ω–∞ PDF:** https://arxiv.org/pdf/1706.03762v7\n",
      "\n",
      "**–ê–Ω–Ω–æ—Ç–∞—Ü–∏—è:**\n",
      "The dominant sequence transduction models are based on complex recurrent or convolutional neural networks in an encoder-decoder configuration. The best performing models also connect the encoder and decoder through an attention mechanism. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. Experiments on two machine translation tasks show these models to be superior in quality while being more parallelizable and requiring significantly less time to train. Our model achieves 28.4 BLEU on the WMT 2014 English-to-German translation task, improving over the existing best results, including ensembles by over 2 BLEU. On the WMT 2014 English-to-French translation task, our model establishes a new single-model state-of-the-art BLEU score of 41.8 after training for 3.5 days on eight GPUs, a small fraction of the training costs of the best models from the literature. We show that the Transformer generalizes well to other tasks by applying it successfully to English constituency parsing both with large and limited training data.\n"
     ]
    }
   ],
   "source": [
    "# –¢–µ—Å—Ç get_paper_details\n",
    "print(\"=== –¢–µ—Å—Ç get_paper_details ===\")\n",
    "print(get_paper_details(\"1706.03762\"))  # Attention Is All You Need"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## –ß–∞—Å—Ç—å 5: –î–∏—Å–ø–µ—Ç—á–µ—Ä –≤—ã–∑–æ–≤–æ–≤ —Ñ—É–Ω–∫—Ü–∏–π\n",
    "\n",
    "–°–æ–∑–¥–∞–¥–∏–º —Ñ—É–Ω–∫—Ü–∏—é-–¥–∏—Å–ø–µ—Ç—á–µ—Ä, –∫–æ—Ç–æ—Ä–∞—è –≤—ã–∑—ã–≤–∞–µ—Ç –Ω—É–∂–Ω—É—é —Ñ—É–Ω–∫—Ü–∏—é –ø–æ –∏–º–µ–Ω–∏:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ –î–∏—Å–ø–µ—Ç—á–µ—Ä —Ñ—É–Ω–∫—Ü–∏–π –≥–æ—Ç–æ–≤\n"
     ]
    }
   ],
   "source": [
    "def execute_arxiv_function(name: str, args: dict) -> str:\n",
    "    \"\"\"\n",
    "    –í—ã–ø–æ–ª–Ω—è–µ—Ç —Ñ—É–Ω–∫—Ü–∏—é arXiv –ø–æ –∏–º–µ–Ω–∏ –∏ –∞—Ä–≥—É–º–µ–Ω—Ç–∞–º.\n",
    "    \"\"\"\n",
    "    if name == \"search_arxiv\":\n",
    "        query = args.get(\"query\", \"\")\n",
    "        field = args.get(\"field\", \"all\")\n",
    "        return search_arxiv(query, field)\n",
    "    \n",
    "    elif name == \"get_paper_details\":\n",
    "        arxiv_id = args.get(\"arxiv_id\", \"\")\n",
    "        return get_paper_details(arxiv_id)\n",
    "    \n",
    "    else:\n",
    "        return f\"–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è: {name}\"\n",
    "\n",
    "print(\"‚úÖ –î–∏—Å–ø–µ—Ç—á–µ—Ä —Ñ—É–Ω–∫—Ü–∏–π –≥–æ—Ç–æ–≤\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## –ß–∞—Å—Ç—å 6: –ü–æ–ª–Ω—ã–π —Ü–∏–∫–ª —Ä–∞–±–æ—Ç—ã —Å –∞–≥–µ–Ω—Ç–æ–º\n",
    "\n",
    "–¢–µ–ø–µ—Ä—å —Å–æ–±–µ—Ä—ë–º –≤—Å—ë –≤–º–µ—Å—Ç–µ: –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º –∑–∞–ø—Ä–æ—Å –º–æ–¥–µ–ª–∏, –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –≤—ã–∑–æ–≤—ã —Ñ—É–Ω–∫—Ü–∏–π, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "instruction = \"\"\"\n",
    "–¢—ã ‚Äî –Ω–∞—É—á–Ω—ã–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç-–∏—Å—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å, –∫–æ—Ç–æ—Ä—ã–π –ø–æ–º–æ–≥–∞–µ—Ç –Ω–∞—Ö–æ–¥–∏—Ç—å –∏ –∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –Ω–∞—É—á–Ω—ã–µ —Å—Ç–∞—Ç—å–∏ –Ω–∞ arXiv.\n",
    "\n",
    "–¢–≤–æ–∏ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏:\n",
    "1. –ü–æ–∏—Å–∫ —Å—Ç–∞—Ç–µ–π –ø–æ –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–∞–º —Å –ø–æ–º–æ—â—å—é —Ñ—É–Ω–∫—Ü–∏–∏ search_arxiv\n",
    "2. –ü–æ–ª—É—á–µ–Ω–∏–µ –ø–æ–¥—Ä–æ–±–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ —Å—Ç–∞—Ç—å–µ –ø–æ –µ—ë arXiv ID —Å –ø–æ–º–æ—â—å—é get_paper_details\n",
    "\n",
    "–ö–æ–≥–¥–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å —Å–ø—Ä–∞—à–∏–≤–∞–µ—Ç –æ –Ω–∞—É—á–Ω–æ–π —Ç–µ–º–µ:\n",
    "1. –°–Ω–∞—á–∞–ª–∞ –≤—ã–ø–æ–ª–Ω–∏ –ø–æ–∏—Å–∫ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö —Å—Ç–∞—Ç–µ–π\n",
    "2. –ï—Å–ª–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –∑–∞–∏–Ω—Ç–µ—Ä–µ—Å—É–µ—Ç—Å—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–π —Å—Ç–∞—Ç—å—ë–π ‚Äî –ø–æ–ª—É—á–∏ –µ—ë –ø–æ–ª–Ω—ã–µ –¥–µ—Ç–∞–ª–∏\n",
    "3. –ü—Ä–µ–¥–æ—Å—Ç–∞–≤—å –∫—Ä–∞—Ç–∫–æ–µ —Ä–µ–∑—é–º–µ –Ω–∞–π–¥–µ–Ω–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ\n",
    "\n",
    "–í—Å–µ–≥–¥–∞ –æ—Ç–≤–µ—á–∞–π –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ –∏ –æ–±—ä—è—Å–Ω—è–π –Ω–∞—É—á–Ω—ã–µ —Ç–µ—Ä–º–∏–Ω—ã –ø–æ–Ω—è—Ç–Ω–æ.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def research_with_agent(prompt: str, max_iterations: int = 10):\n",
    "    \"\"\"\n",
    "    –û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –∞–≥–µ–Ω—Ç–æ–º-–∏—Å—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª–µ–º.\n",
    "    \"\"\"\n",
    "    print(f\"üî¨ –ó–∞–ø—Ä–æ—Å: {prompt}\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # –ù–∞—á–∞–ª—å–Ω—ã–π –∑–∞–ø—Ä–æ—Å\n",
    "    res = client.responses.create(\n",
    "        model=model,\n",
    "        tools=arxiv_tools,\n",
    "        instructions=instruction,\n",
    "        store=True,\n",
    "        input=prompt\n",
    "    )\n",
    "    \n",
    "    iteration = 0\n",
    "    \n",
    "    while iteration < max_iterations:\n",
    "        # –ò—â–µ–º –≤—ã–∑–æ–≤—ã —Ñ—É–Ω–∫—Ü–∏–π\n",
    "        tool_calls = [item for item in res.output if item.type == \"function_call\"]\n",
    "        \n",
    "        if not tool_calls:\n",
    "            # –ú–æ–¥–µ–ª—å –∑–∞–∫–æ–Ω—á–∏–ª–∞ ‚Äî –≤—ã–≤–æ–¥–∏–º —Ñ–∏–Ω–∞–ª—å–Ω—ã–π –æ—Ç–≤–µ—Ç\n",
    "            break\n",
    "        \n",
    "        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∫–∞–∂–¥—ã–π –≤—ã–∑–æ–≤ —Ñ—É–Ω–∫—Ü–∏–∏\n",
    "        outputs = []\n",
    "        for call in tool_calls:\n",
    "            # –ü–∞—Ä—Å–∏–º –∞—Ä–≥—É–º–µ–Ω—Ç—ã\n",
    "            args = json.loads(call.arguments) if call.arguments else {}\n",
    "            \n",
    "            print(f\"üìö –í—ã–∑–æ–≤: {call.name}({args})\")\n",
    "            \n",
    "            # –í—ã–ø–æ–ª–Ω—è–µ–º —Ñ—É–Ω–∫—Ü–∏—é\n",
    "            result = execute_arxiv_function(call.name, args)\n",
    "            print(f\"üìÑ –†–µ–∑—É–ª—å—Ç–∞—Ç –ø–æ–ª—É—á–µ–Ω ({len(result)} —Å–∏–º–≤–æ–ª–æ–≤)\")\n",
    "            \n",
    "            # –§–æ—Ä–º–∏—Ä—É–µ–º –æ—Ç–≤–µ—Ç –¥–ª—è –º–æ–¥–µ–ª–∏\n",
    "            outputs.append({\n",
    "                \"type\": \"function_call_output\",\n",
    "                \"call_id\": call.call_id,\n",
    "                \"output\": result\n",
    "            })\n",
    "        \n",
    "        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –º–æ–¥–µ–ª–∏\n",
    "        res = client.responses.create(\n",
    "            model=model,\n",
    "            tools=arxiv_tools,\n",
    "            previous_response_id=res.id,\n",
    "            store=True,\n",
    "            input=outputs\n",
    "        )\n",
    "        \n",
    "        iteration += 1\n",
    "    \n",
    "    print(\"=\" * 60)\n",
    "    printx(res.output_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### –¢–µ—Å—Ç: –ø–æ–∏—Å–∫ —Å—Ç–∞—Ç–µ–π"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üî¨ –ó–∞–ø—Ä–æ—Å: –ù–∞–π–¥–∏ –ø–æ—Å–ª–µ–¥–Ω–∏–µ —Å—Ç–∞—Ç—å–∏ –ø—Ä–æ large language models –∏ —Ä–∞—Å—Å–∫–∞–∂–∏ –æ —Å–∞–º–æ–π –∏–Ω—Ç–µ—Ä–µ—Å–Ω–æ–π\n",
      "============================================================\n",
      "üìö –í—ã–∑–æ–≤: search_arxiv({'query': 'large language models', 'field': 'all'})\n",
      "üìÑ –†–µ–∑—É–ª—å—Ç–∞—Ç –ø–æ–ª—É—á–µ–Ω (1479 —Å–∏–º–≤–æ–ª–æ–≤)\n",
      "üìö –í—ã–∑–æ–≤: get_paper_details({'arxiv_id': '2403.09676v1'})\n",
      "üìÑ –†–µ–∑—É–ª—å—Ç–∞—Ç –ø–æ–ª—É—á–µ–Ω (1331 —Å–∏–º–≤–æ–ª–æ–≤)\n",
      "============================================================\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "–°—Ä–µ–¥–∏ –ø–æ—Å–ª–µ–¥–Ω–∏—Ö —Å—Ç–∞—Ç–µ–π –æ –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª—è—Ö (LLMs) –æ—Å–æ–±–µ–Ω–Ω–æ –≤—ã–¥–µ–ª—è–µ—Ç—Å—è —Ä–∞–±–æ—Ç–∞ **\"Unmasking the Shadows of AI: Investigating Deceptive Capabilities in Large Language Models\"** (arXiv:2403.09676v1) –õ–∏–Ω—å–≥–µ –ì–æ.\n",
       "\n",
       "### –û —á—ë–º —ç—Ç–∞ —Å—Ç–∞—Ç—å—è?\n",
       "\n",
       "–ò—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ –ø–æ—Å–≤—è—â–µ–Ω–æ **–æ–±–º–∞–Ω—á–∏–≤—ã–º —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç—è–º –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π** ‚Äî –æ–¥–Ω–æ–π –∏–∑ —Å–∞–º—ã—Ö –æ—Å—Ç—Ä—ã—Ö –∏ —ç—Ç–∏—á–µ—Å–∫–∏ —Å–ª–æ–∂–Ω—ã—Ö —Ç–µ–º –≤ —Å–æ–≤—Ä–µ–º–µ–Ω–Ω–æ–º –ò–ò. –ê–≤—Ç–æ—Ä –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç, –∫–∞–∫ –∏ –ø–æ—á–µ–º—É LLM –º–æ–≥—É—Ç –≤–µ—Å—Ç–∏ —Å–µ–±—è –æ–±–º–∞–Ω—á–∏–≤–æ, –∫–∞–∫–∏–µ —Ä–∏—Å–∫–∏ —ç—Ç–æ –Ω–µ—Å—ë—Ç –∏ –∫–∞–∫ —Å —ç—Ç–∏–º –º–æ–∂–Ω–æ –±–æ—Ä–æ—Ç—å—Å—è.\n",
       "\n",
       "### –ö–ª—é—á–µ–≤—ã–µ –∏–¥–µ–∏:\n",
       "\n",
       "1. **–ö–∞—Ç–µ–≥–æ—Ä–∏–∏ –æ–±–º–∞–Ω–∞ –≤ –ò–ò:**\n",
       "   - **–°—Ç—Ä–∞—Ç–µ–≥–∏—á–µ—Å–∫–∏–π –æ–±–º–∞–Ω** ‚Äî –º–æ–¥–µ–ª—å —Å–æ–∑–Ω–∞—Ç–µ–ª—å–Ω–æ –∏—Å–∫–∞–∂–∞–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –¥–ª—è –¥–æ—Å—Ç–∏–∂–µ–Ω–∏—è —Ü–µ–ª–∏.\n",
       "   - **–ü–æ–¥—Ä–∞–∂–∞–Ω–∏–µ (Imitation)** ‚Äî –º–æ–¥–µ–ª—å –∫–æ–ø–∏—Ä—É–µ—Ç —Å—Ç–∏–ª—å –∏–ª–∏ –ø–æ–≤–µ–¥–µ–Ω–∏–µ, –∫–æ—Ç–æ—Ä–æ–µ –º–æ–∂–µ—Ç –≤–≤–æ–¥–∏—Ç—å –≤ –∑–∞–±–ª—É–∂–¥–µ–Ω–∏–µ.\n",
       "   - **–£–≥–æ–¥–Ω–∏—á–µ—Å—Ç–≤–æ (Sycophancy)** ‚Äî –º–æ–¥–µ–ª—å –≥–æ–≤–æ—Ä–∏—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é —Ç–æ, —á—Ç–æ –æ–Ω —Ö–æ—á–µ—Ç —É—Å–ª—ã—à–∞—Ç—å, –≤–º–µ—Å—Ç–æ –ø—Ä–∞–≤–¥—ã.\n",
       "   - **–ù–µ–¥–æ–±—Ä–æ—Å–æ–≤–µ—Å—Ç–Ω–æ–µ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–µ (Unfaithful Reasoning)** ‚Äî –º–æ–¥–µ–ª—å –≤—ã–¥–∞—ë—Ç –ª–æ–≥–∏—á–Ω—ã–π –Ω–∞ –≤–∏–¥ –æ—Ç–≤–µ—Ç, –Ω–æ —Å –≤–Ω—É—Ç—Ä–µ–Ω–Ω–∏–º–∏ –æ—à–∏–±–∫–∞–º–∏ –≤ —Ö–æ–¥–µ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏—è.\n",
       "\n",
       "2. **–ò—Å—Ç–æ—á–Ω–∏–∫–∏ –ø—Ä–æ–±–ª–µ–º—ã:**\n",
       "   - –ú–Ω–æ–≥–æ—É—Ä–æ–≤–Ω–µ–≤—ã–µ **–ø—Ä–µ–¥–≤–∑—è—Ç–æ—Å—Ç–∏** –≤ –¥–∞–Ω–Ω—ã—Ö –æ–±—É—á–µ–Ω–∏—è.\n",
       "   - –î–∞–≤–ª–µ–Ω–∏–µ –Ω–∞ –º–æ–¥–µ–ª—å \"—É–≥–æ–¥–∏—Ç—å\" –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é.\n",
       "   - –û—Ç—Å—É—Ç—Å—Ç–≤–∏–µ –∏—Å—Ç–∏–Ω–Ω–æ–≥–æ –ø–æ–Ω–∏–º–∞–Ω–∏—è, —á—Ç–æ –ø—Ä–∏–≤–æ–¥–∏—Ç –∫ –≥–∞–ª–ª—é—Ü–∏–Ω–∞—Ü–∏—è–º.\n",
       "\n",
       "3. **–†–∏—Å–∫–∏ –∏ –ø–æ—Å–ª–µ–¥—Å—Ç–≤–∏—è:**\n",
       "   - –†–∞—Å–ø—Ä–æ—Å—Ç—Ä–∞–Ω–µ–Ω–∏–µ –¥–µ–∑–∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏.\n",
       "   - –ú–∞–Ω–∏–ø—É–ª—è—Ü–∏–∏ –≤ –ø–æ–ª–∏—Ç–∏–∫–µ, –æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–∏, –º–µ–¥–∏—Ü–∏–Ω–µ.\n",
       "   - –ü–æ–¥—Ä—ã–≤ –¥–æ–≤–µ—Ä–∏—è –∫ –ò–ò-—Å–∏—Å—Ç–µ–º–∞–º.\n",
       "\n",
       "4. **–†–µ—à–µ–Ω–∏—è:**\n",
       "   - –ú–µ–∂–¥—É–Ω–∞—Ä–æ–¥–Ω–æ–µ —Ä–µ–≥—É–ª–∏—Ä–æ–≤–∞–Ω–∏–µ –∏ **—Å–æ–≤–º–µ—Å—Ç–Ω–æ–µ —É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –ò–ò**.\n",
       "   - –ü–µ—Ä–µ—Å–º–æ—Ç—Ä –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è –ª—é–¥–µ–π —Å –ò–ò: –æ–±—É—á–µ–Ω–∏–µ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–æ–º—É –º—ã—à–ª–µ–Ω–∏—é.\n",
       "   - –í–Ω–µ–¥—Ä–µ–Ω–∏–µ **—Ü–∏—Ñ—Ä–æ–≤–æ–≥–æ –ø—Ä–æ—Å–≤–µ—â–µ–Ω–∏—è** –∏ —ç—Ç–∏—á–µ—Å–∫–∏—Ö –Ω–æ—Ä–º –≤ —Ä–∞–∑—Ä–∞–±–æ—Ç–∫—É –º–æ–¥–µ–ª–µ–π.\n",
       "\n",
       "### –ü–æ—á–µ–º—É —ç—Ç–æ –∏–Ω—Ç–µ—Ä–µ—Å–Ω–æ?\n",
       "\n",
       "–≠—Ç–∞ —Å—Ç–∞—Ç—å—è –≤—ã—Ö–æ–¥–∏—Ç –∑–∞ —Ä–∞–º–∫–∏ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏—Ö –¥–µ—Ç–∞–ª–µ–π –∏ –∑–∞—Ç—Ä–∞–≥–∏–≤–∞–µ—Ç **–≥–ª—É–±–æ–∫–∏–µ —ç—Ç–∏—á–µ—Å–∫–∏–µ –∏ —Å–æ—Ü–∏–∞–ª—å–Ω—ã–µ –≤–æ–ø—Ä–æ—Å—ã**. –û–Ω–∞ –ø–æ–¥—á—ë—Ä–∫–∏–≤–∞–µ—Ç, —á—Ç–æ –¥–∞–∂–µ –µ—Å–ª–∏ LLM –Ω–µ ¬´—Å–æ–∑–Ω–∞—Ç–µ–ª—å–Ω—ã¬ª, –∏—Ö –ø–æ–≤–µ–¥–µ–Ω–∏–µ –º–æ–∂–µ—Ç –±—ã—Ç—å *—Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω–æ –æ–±–º–∞–Ω—á–∏–≤—ã–º* ‚Äî –∏ —ç—Ç–æ —É–∂–µ —Ç—Ä–µ–±—É–µ—Ç —Å–µ—Ä—å—ë–∑–Ω–æ–≥–æ —Ä–µ–∞–≥–∏—Ä–æ–≤–∞–Ω–∏—è —Å–æ —Å—Ç–æ—Ä–æ–Ω—ã —Ä–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫–æ–≤, —Ä–µ–≥—É–ª—è—Ç–æ—Ä–æ–≤ –∏ –æ–±—â–µ—Å—Ç–≤–∞.\n",
       "\n",
       "–ï—Å–ª–∏ –≤—ã –∏–Ω—Ç–µ—Ä–µ—Å—É–µ—Ç–µ—Å—å –Ω–µ —Ç–æ–ª—å–∫–æ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—è–º–∏ –ò–ò, –Ω–æ –∏ –µ–≥–æ —Ç–µ–Ω–µ–≤—ã–º–∏ —Å—Ç–æ—Ä–æ–Ω–∞–º–∏ ‚Äî —ç—Ç–∞ —Ä–∞–±–æ—Ç–∞ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω–∞ –∫ –æ–∑–Ω–∞–∫–æ–º–ª–µ–Ω–∏—é."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "research_with_agent(\"–ù–∞–π–¥–∏ –ø–æ—Å–ª–µ–¥–Ω–∏–µ —Å—Ç–∞—Ç—å–∏ –ø—Ä–æ large language models –∏ —Ä–∞—Å—Å–∫–∞–∂–∏ –æ —Å–∞–º–æ–π –∏–Ω—Ç–µ—Ä–µ—Å–Ω–æ–π\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "research_with_agent(\"–ß—Ç–æ –Ω–æ–≤–æ–≥–æ –≤ –æ–±–ª–∞—Å—Ç–∏ –Ω–µ–π—Ä–æ—Å–µ—Ç–µ–≤–æ–π –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## –ß–∞—Å—Ç—å 7: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ Pydantic –¥–ª—è –æ–ø–∏—Å–∞–Ω–∏—è —Ñ—É–Ω–∫—Ü–∏–π\n",
    "\n",
    "–ö–∞–∫ –∏ –≤ –ø—Ä–µ–¥—ã–¥—É—â–µ–º –Ω–æ—É—Ç–±—É–∫–µ, –∏—Å–ø–æ–ª—å–∑—É–µ–º Pydantic –¥–ª—è –±–æ–ª–µ–µ —á–∏—Å—Ç–æ–≥–æ –∫–æ–¥–∞:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Pydantic-–º–æ–¥–µ–ª–∏ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω—ã\n"
     ]
    }
   ],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from typing import Literal, Optional\n",
    "\n",
    "\n",
    "class SearchArxiv(BaseModel):\n",
    "    \"\"\"–ü–æ–∏—Å–∫ –Ω–∞—É—á–Ω—ã—Ö —Å—Ç–∞—Ç–µ–π –Ω–∞ arXiv –ø–æ –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–∞–º. –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ç–æ–ø-3 –Ω–∞–∏–±–æ–ª–µ–µ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö —Å—Ç–∞—Ç—å–∏.\"\"\"\n",
    "    \n",
    "    query: str = Field(\n",
    "        description=\"–ü–æ–∏—Å–∫–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å –Ω–∞ –∞–Ω–≥–ª–∏–π—Å–∫–æ–º —è–∑—ã–∫–µ. –ö–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ —á–µ—Ä–µ–∑ –ø—Ä–æ–±–µ–ª.\"\n",
    "    )\n",
    "    field: Literal[\"all\", \"title\", \"abstract\", \"author\"] = Field(\n",
    "        default=\"all\",\n",
    "        description=\"–ü–æ–ª–µ –¥–ª—è –ø–æ–∏—Å–∫–∞: all (–≤—Å–µ –ø–æ–ª—è), title (–∑–∞–≥–æ–ª–æ–≤–æ–∫), abstract (–∞–Ω–Ω–æ—Ç–∞—Ü–∏—è), author (–∞–≤—Ç–æ—Ä)\"\n",
    "    )\n",
    "    \n",
    "    def execute(self) -> str:\n",
    "        return search_arxiv(self.query, self.field)\n",
    "\n",
    "\n",
    "class GetPaperDetails(BaseModel):\n",
    "    \"\"\"–ü–æ–ª—É—á–∏—Ç—å –ø–æ–ª–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Å—Ç–∞—Ç—å–µ –ø–æ –µ—ë arXiv ID, –≤–∫–ª—é—á–∞—è –ø–æ–ª–Ω—É—é –∞–Ω–Ω–æ—Ç–∞—Ü–∏—é.\"\"\"\n",
    "    \n",
    "    arxiv_id: str = Field(\n",
    "        description=\"–ò–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä —Å—Ç–∞—Ç—å–∏ –Ω–∞ arXiv (–Ω–∞–ø—Ä–∏–º–µ—Ä, 2304.12345 –∏–ª–∏ 1706.03762)\"\n",
    "    )\n",
    "    \n",
    "    def execute(self) -> str:\n",
    "        return get_paper_details(self.arxiv_id)\n",
    "\n",
    "\n",
    "# –°–ø–∏—Å–æ–∫ –≤—Å–µ—Ö –∫–ª–∞—Å—Å–æ–≤-–∫–æ–º–∞–Ω–¥\n",
    "ARXIV_COMMANDS = [SearchArxiv, GetPaperDetails]\n",
    "\n",
    "print(\"‚úÖ Pydantic-–º–æ–¥–µ–ª–∏ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω—ã\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## –ß–∞—Å—Ç—å 8: –ö–ª–∞—Å—Å Agent\n",
    "\n",
    "–°–æ–∑–¥–∞–¥–∏–º —É–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π –∫–ª–∞—Å—Å `Agent`, –∫–æ—Ç–æ—Ä—ã–π –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –≤—ã–∑–æ–≤—ã —Ñ—É–Ω–∫—Ü–∏–π:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ –ö–ª–∞—Å—Å Agent –æ–ø—Ä–µ–¥–µ–ª—ë–Ω\n"
     ]
    }
   ],
   "source": [
    "class Agent:\n",
    "    \"\"\"\n",
    "    –£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π –∞–≥–µ–Ω—Ç —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π Function Calling.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, instruction: str, tools: list, model: str = model, max_iterations: int = 20):\n",
    "        self.instruction = instruction\n",
    "        self.model = model\n",
    "        self.max_iterations = max_iterations\n",
    "        \n",
    "        # –°–æ–∑–¥–∞—ë–º —Å–ª–æ–≤–∞—Ä—å –∏–º—è -> –∫–ª–∞—Å—Å\n",
    "        self.tool_map = {cls.__name__: cls for cls in tools}\n",
    "        \n",
    "        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –æ–ø–∏—Å–∞–Ω–∏—è –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤\n",
    "        self.tools_schema = [\n",
    "            {\n",
    "                \"type\": \"function\",\n",
    "                \"name\": cls.__name__,\n",
    "                \"description\": cls.__doc__ or \"\",\n",
    "                \"parameters\": cls.model_json_schema()\n",
    "            }\n",
    "            for cls in tools\n",
    "        ]\n",
    "        \n",
    "        # –ò—Å—Ç–æ—Ä–∏—è —Å–µ—Å—Å–∏–π\n",
    "        self.sessions = {}\n",
    "    \n",
    "    def __call__(self, message: str, session_id: str = \"default\", verbose: bool = True) -> str:\n",
    "        \"\"\"\n",
    "        –û–±—Ä–∞–±–æ—Ç–∫–∞ —Å–æ–æ–±—â–µ–Ω–∏—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è —Å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–º –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ–º —Ñ—É–Ω–∫—Ü–∏–π.\n",
    "        \"\"\"\n",
    "        session = self.sessions.get(session_id, {\"last_response_id\": None})\n",
    "        \n",
    "        # –ü–µ—Ä–≤—ã–π –∑–∞–ø—Ä–æ—Å\n",
    "        res = client.responses.create(\n",
    "            model=self.model,\n",
    "            tools=self.tools_schema,\n",
    "            instructions=self.instruction,\n",
    "            previous_response_id=session[\"last_response_id\"],\n",
    "            store=True,\n",
    "            input=message\n",
    "        )\n",
    "        \n",
    "        # –¶–∏–∫–ª –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ñ—É–Ω–∫—Ü–∏–π\n",
    "        for _ in range(self.max_iterations):\n",
    "            tool_calls = [item for item in res.output if item.type == \"function_call\"]\n",
    "            \n",
    "            if not tool_calls:\n",
    "                break\n",
    "            \n",
    "            # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –≤—ã–∑–æ–≤—ã\n",
    "            outputs = []\n",
    "            for call in tool_calls:\n",
    "                if verbose:\n",
    "                    print(f\"  üîß {call.name}({call.arguments})\")\n",
    "                \n",
    "                try:\n",
    "                    cls = self.tool_map[call.name]\n",
    "                    args = json.loads(call.arguments) if call.arguments else {}\n",
    "                    obj = cls.model_validate(args)\n",
    "                    result = obj.execute()\n",
    "                except Exception as e:\n",
    "                    result = f\"–û—à–∏–±–∫–∞: {e}\"\n",
    "                \n",
    "                outputs.append({\n",
    "                    \"type\": \"function_call_output\",\n",
    "                    \"call_id\": call.call_id,\n",
    "                    \"output\": result\n",
    "                })\n",
    "            \n",
    "            # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã\n",
    "            res = client.responses.create(\n",
    "                model=self.model,\n",
    "                tools=self.tools_schema,\n",
    "                previous_response_id=res.id,\n",
    "                store=True,\n",
    "                input=outputs\n",
    "            )\n",
    "        \n",
    "        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å–æ—Å—Ç–æ—è–Ω–∏–µ —Å–µ—Å—Å–∏–∏\n",
    "        session[\"last_response_id\"] = res.id\n",
    "        self.sessions[session_id] = session\n",
    "        \n",
    "        return res.output_text or \"–ì–æ—Ç–æ–≤–æ!\"\n",
    "\n",
    "print(\"‚úÖ –ö–ª–∞—Å—Å Agent –æ–ø—Ä–µ–¥–µ–ª—ë–Ω\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## –ß–∞—Å—Ç—å 9: –°–æ–∑–¥–∞–Ω–∏–µ –∞–≥–µ–Ω—Ç–∞-–∏—Å—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—è\n",
    "\n",
    "–¢–µ–ø–µ—Ä—å —Å–æ–∑–¥–∞–¥–∏–º –∞–≥–µ–Ω—Ç–∞ —Å –ø–æ–º–æ—â—å—é –Ω–∞—à–µ–≥–æ –∫–ª–∞—Å—Å–∞:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üî¨ –ê–≥–µ–Ω—Ç-–∏—Å—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å –≥–æ—Ç–æ–≤ –∫ —Ä–∞–±–æ—Ç–µ!\n"
     ]
    }
   ],
   "source": [
    "researcher_instruction = \"\"\"\n",
    "–¢—ã ‚Äî –Ω–∞—É—á–Ω—ã–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç-–∏—Å—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å, —ç–∫—Å–ø–µ—Ä—Ç –ø–æ –ø–æ–∏—Å–∫—É –∏ –∞–Ω–∞–ª–∏–∑—É –Ω–∞—É—á–Ω—ã—Ö —Å—Ç–∞—Ç–µ–π –Ω–∞ arXiv.\n",
    "\n",
    "–¢–≤–æ–∏ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏:\n",
    "- SearchArxiv: –ø–æ–∏—Å–∫ —Å—Ç–∞—Ç–µ–π –ø–æ –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–∞–º (–∏—Å–ø–æ–ª—å–∑—É–π –∞–Ω–≥–ª–∏–π—Å–∫–∏–µ —Ç–µ—Ä–º–∏–Ω—ã –¥–ª—è –ª—É—á—à–∏—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤)\n",
    "- GetPaperDetails: –ø–æ–ª—É—á–µ–Ω–∏–µ –ø–æ–ª–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–π —Å—Ç–∞—Ç—å–µ –ø–æ arXiv ID\n",
    "\n",
    "–°—Ç—Ä–∞—Ç–µ–≥–∏—è —Ä–∞–±–æ—Ç—ã:\n",
    "1. –ö–æ–≥–¥–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å —Å–ø—Ä–∞—à–∏–≤–∞–µ—Ç –æ —Ç–µ–º–µ ‚Äî —Å–Ω–∞—á–∞–ª–∞ –∏—â–∏ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ —Å—Ç–∞—Ç—å–∏\n",
    "2. –í—ã–±–µ—Ä–∏ —Å–∞–º—É—é –∏–Ω—Ç–µ—Ä–µ—Å–Ω—É—é/—Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—É—é —Å—Ç–∞—Ç—å—é –∏–∑ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö\n",
    "3. –ü–æ–ª—É—á–∏ –ø–æ–¥—Ä–æ–±–Ω–æ—Å—Ç–∏ –æ–± —ç—Ç–æ–π —Å—Ç–∞—Ç—å–µ\n",
    "4. –°–æ—Å—Ç–∞–≤—å –∫—Ä–∞—Ç–∫–æ–µ —Ä–µ–∑—é–º–µ –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ\n",
    "\n",
    "–í —Ä–µ–∑—é–º–µ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ —É–∫–∞–∂–∏:\n",
    "- –ù–∞–∑–≤–∞–Ω–∏–µ —Å—Ç–∞—Ç—å–∏\n",
    "- –ê–≤—Ç–æ—Ä–æ–≤\n",
    "- –ö–ª—é—á–µ–≤—ã–µ –∏–¥–µ–∏ –∏ –≤—ã–≤–æ–¥—ã\n",
    "- –ü–æ—á–µ–º—É —ç—Ç–∞ —Ä–∞–±–æ—Ç–∞ –≤–∞–∂–Ω–∞\n",
    "\n",
    "–û–±—ä—è—Å–Ω—è–π –Ω–∞—É—á–Ω—ã–µ —Ç–µ—Ä–º–∏–Ω—ã –ø–æ–Ω—è—Ç–Ω—ã–º —è–∑—ã–∫–æ–º.\n",
    "\"\"\"\n",
    "\n",
    "# –°–æ–∑–¥–∞—ë–º –∞–≥–µ–Ω—Ç–∞\n",
    "researcher = Agent(\n",
    "    instruction=researcher_instruction,\n",
    "    tools=ARXIV_COMMANDS\n",
    ")\n",
    "\n",
    "print(\"üî¨ –ê–≥–µ–Ω—Ç-–∏—Å—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å –≥–æ—Ç–æ–≤ –∫ —Ä–∞–±–æ—Ç–µ!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## –ß–∞—Å—Ç—å 10: –ü—Ä–∏–º–µ—Ä—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è\n",
    "\n",
    "–¢–µ–ø–µ—Ä—å –∫–æ–¥ —Å—Ç–∞–ª –Ω–∞–º–Ω–æ–≥–æ –ø—Ä–æ—â–µ –±–ª–∞–≥–æ–¥–∞—Ä—è –∫–ª–∞—Å—Å—É Agent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def research(topic: str):\n",
    "    \"\"\"–£–¥–æ–±–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è —Ç–µ–º—ã.\"\"\"\n",
    "    print(f\"üî¨ –ò—Å—Å–ª–µ–¥—É–µ–º: {topic}\")\n",
    "    print(\"=\" * 60)\n",
    "    result = researcher(topic)\n",
    "    print(\"=\" * 60)\n",
    "    printx(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üî¨ –ò—Å—Å–ª–µ–¥—É–µ–º: –†–∞—Å—Å–∫–∞–∂–∏ –ø—Ä–æ –ø–æ—Å–ª–µ–¥–Ω–∏–µ –¥–æ—Å—Ç–∏–∂–µ–Ω–∏—è –≤ –æ–±–ª–∞—Å—Ç–∏ reinforcement learning\n",
      "============================================================\n",
      "  üîß SearchArxiv({\"query\": \"reinforcement learning recent advances\", \"field\": \"all\"})\n",
      "  üîß GetPaperDetails({\"arxiv_id\": \"1912.03821v1\"})\n",
      "  üîß GetPaperDetails({\"arxiv_id\": \"1908.09381v5\"})\n",
      "  üîß GetPaperDetails({\"arxiv_id\": \"1712.00006v2\"})\n",
      "============================================================\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "–ù–∞ –æ—Å–Ω–æ–≤–µ –∞–Ω–∞–ª–∏–∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏—Ö –Ω–∞—É—á–Ω—ã—Ö –ø—É–±–ª–∏–∫–∞—Ü–∏–π, –≤–æ—Ç –æ–±–∑–æ—Ä –∫–ª—é—á–µ–≤—ã—Ö –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–π –∏ –¥–æ—Å—Ç–∏–∂–µ–Ω–∏–π –≤ –æ–±–ª–∞—Å—Ç–∏ **–æ–±—É—á–µ–Ω–∏—è —Å –ø–æ–¥–∫—Ä–µ–ø–ª–µ–Ω–∏–µ–º (reinforcement learning, RL)**:\n",
       "\n",
       "---\n",
       "\n",
       "### 1. **–ú–Ω–æ–≥–æ–∞–≥–µ–Ω—Ç–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ —Å –ø–æ–¥–∫—Ä–µ–ø–ª–µ–Ω–∏–µ–º (MARL)**\n",
       "–û–¥–Ω–æ–π –∏–∑ –∞–∫—Ç–∏–≤–Ω–æ —Ä–∞–∑–≤–∏–≤–∞—é—â–∏—Ö—Å—è –æ–±–ª–∞—Å—Ç–µ–π —è–≤–ª—è–µ—Ç—Å—è **–¥–µ—Ü–µ–Ω—Ç—Ä–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ —Å –ø–æ–¥–∫—Ä–µ–ø–ª–µ–Ω–∏–µ–º –≤ —Å–∏—Å—Ç–µ–º–∞—Ö —Å —Å–µ—Ç–µ–≤—ã–º–∏ –∞–≥–µ–Ω—Ç–∞–º–∏** (Decentralized Multi-Agent RL). –í —Ç–∞–∫–∏—Ö —Å–∏—Å—Ç–µ–º–∞—Ö –º–Ω–æ–∂–µ—Å—Ç–≤–æ –∞–≥–µ–Ω—Ç–æ–≤ –¥–µ–π—Å—Ç–≤—É–µ—Ç –≤ –æ–±—â–µ–π —Å—Ä–µ–¥–µ, –Ω–µ –∏–º–µ—è —Ü–µ–Ω—Ç—Ä–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–æ–≥–æ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç–æ—Ä–∞. –í–º–µ—Å—Ç–æ —ç—Ç–æ–≥–æ –æ–Ω–∏ –æ–±–º–µ–Ω–∏–≤–∞—é—Ç—Å—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π —Ç–æ–ª—å–∫–æ —Å —Å–æ—Å–µ–¥—è–º–∏ –ø–æ —Å–µ—Ç–∏.\n",
       "\n",
       "- **–ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ:** —É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ —Ä–æ–±–æ—Ç–∞–º–∏, –±–µ—Å–ø–∏–ª–æ—Ç–Ω—ã–º–∏ –∞–≤—Ç–æ–º–æ–±–∏–ª—è–º–∏, —Å–µ–Ω—Å–æ—Ä–Ω—ã–º–∏ —Å–µ—Ç—è–º–∏, —É–º–Ω—ã–º–∏ —ç–ª–µ–∫—Ç—Ä–æ—Å–µ—Ç—è–º–∏.\n",
       "- **–ü—Ä–æ–±–ª–µ–º—ã:** –æ—Ç—Å—É—Ç—Å—Ç–≤–∏–µ –≥–ª–æ–±–∞–ª—å–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏, –∑–∞–¥–µ—Ä–∂–∫–∏ –≤ –∫–æ–º–º—É–Ω–∏–∫–∞—Ü–∏–∏, –º–∞—Å—à—Ç–∞–±–∏—Ä—É–µ–º–æ—Å—Ç—å.\n",
       "- **–ù–æ–≤–µ–π—à–∏–µ –ø–æ–¥—Ö–æ–¥—ã:** —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∞ –∞–ª–≥–æ—Ä–∏—Ç–º–æ–≤, –æ–±–µ—Å–ø–µ—á–∏–≤–∞—é—â–∏—Ö —Å—Ö–æ–¥–∏–º–æ—Å—Ç—å –∏ —É—Å—Ç–æ–π—á–∏–≤–æ—Å—Ç—å –¥–∞–∂–µ –ø—Ä–∏ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–Ω–æ–π —Å–≤—è–∑–∏ –º–µ–∂–¥—É –∞–≥–µ–Ω—Ç–∞–º–∏.\n",
       "- **–ò—Å—Ç–æ—á–Ω–∏–∫:** Zhang, Yang, Ba≈üar ‚Äî *Decentralized Multi-Agent RL with Networked Agents* (2019).\n",
       "\n",
       "---\n",
       "\n",
       "### 2. **–ì–ª—É–±–æ–∫–æ–µ –æ–±—É—á–µ–Ω–∏–µ —Å –ø–æ–¥–∫—Ä–µ–ø–ª–µ–Ω–∏–µ–º –∏ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–Ω—ã–µ –º–æ–¥–µ–ª–∏**\n",
       "–í—Ç–æ—Ä–æ–µ –≤–∞–∂–Ω–æ–µ –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–µ ‚Äî –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è **–≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–Ω—ã—Ö –≥—Ä–∞—Ñ–∏—á–µ—Å–∫–∏—Ö –º–æ–¥–µ–ª–µ–π (PGM)** –∏ **–≤–∞—Ä–∏–∞—Ü–∏–æ–Ω–Ω–æ–≥–æ –≤—ã–≤–æ–¥–∞** –≤ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã –≥–ª—É–±–æ–∫–æ–≥–æ RL.\n",
       "\n",
       "- –≠—Ç–æ –ø–æ–∑–≤–æ–ª—è–µ—Ç –º–æ–¥–µ–ª—è–º –ª—É—á—à–µ —Å–ø—Ä–∞–≤–ª—è—Ç—å—Å—è —Å **–Ω–µ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω–æ—Å—Ç—å—é**, **–æ–±–æ–±—â–µ–Ω–∏–µ–º** –∏ **—ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω—ã–º –æ–±—É—á–µ–Ω–∏–µ–º**.\n",
       "- –¢–∞–∫–∏–µ –ø–æ–¥—Ö–æ–¥—ã –ø—Ä–∏–º–µ–Ω—è—é—Ç—Å—è, –Ω–∞–ø—Ä–∏–º–µ—Ä, –≤ **–º–æ–¥–µ–ª—å–Ω–æ-–æ—Ä–∏–µ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–Ω–æ–º RL**, –≥–¥–µ –∞–≥–µ–Ω—Ç —Å—Ç—Ä–æ–∏—Ç –≤–Ω—É—Ç—Ä–µ–Ω–Ω—é—é –º–æ–¥–µ–ª—å —Å—Ä–µ–¥—ã.\n",
       "- –ú–µ—Ç–æ–¥—ã –≤–∫–ª—é—á–∞—é—Ç: **Variational Autoencoders (VAE)** –≤ –ø–æ–ª–∏—Ç–∏–∫–µ, **Bayesian Neural Networks**, **Stochastic Policies**.\n",
       "- **–ò—Å—Ç–æ—á–Ω–∏–∫:** Sun, Bischl ‚Äî *Tutorial on PGM and Variational Inference in Deep RL* (2019).\n",
       "\n",
       "---\n",
       "\n",
       "### 3. **–°—Ä–∞–≤–Ω–µ–Ω–∏–µ RL –∏ —ç–≤–æ–ª—é—Ü–∏–æ–Ω–Ω—ã—Ö —Å—Ç—Ä–∞—Ç–µ–≥–∏–π**\n",
       "–ï—â—ë –æ–¥–Ω–æ –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–µ ‚Äî —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ –∏ —Å–∏–Ω–µ—Ä–≥–∏—è –º–µ–∂–¥—É **–≥–ª—É–±–æ–∫–∏–º –æ–±—É—á–µ–Ω–∏–µ–º —Å –ø–æ–¥–∫—Ä–µ–ø–ª–µ–Ω–∏–µ–º** –∏ **—ç–≤–æ–ª—é—Ü–∏–æ–Ω–Ω—ã–º–∏ –º–µ—Ç–æ–¥–∞–º–∏** (–Ω–∞–ø—Ä–∏–º–µ—Ä, —ç–≤–æ–ª—é—Ü–∏–æ–Ω–Ω—ã–µ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏, –≥–µ–Ω–µ—Ç–∏—á–µ—Å–∫–∏–µ –∞–ª–≥–æ—Ä–∏—Ç–º—ã).\n",
       "\n",
       "- –ò—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è –ø–æ–∫–∞–∑—ã–≤–∞—é—Ç, —á—Ç–æ **–Ω–∏ –æ–¥–∏–Ω –∏–∑ –ø–æ–¥—Ö–æ–¥–æ–≤ –Ω–µ —è–≤–ª—è–µ—Ç—Å—è —É–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω–æ –ª—É—á—à–∏–º**.\n",
       "- –ù–∞–ø—Ä–∏–º–µ—Ä, **PPO (Proximal Policy Optimization)** –∏ **DDPG (Deep Deterministic Policy Gradient)** ‚Äî —Å–∏–ª—å–Ω—ã–µ RL-–º–µ—Ç–æ–¥—ã.\n",
       "- –≠–≤–æ–ª—é—Ü–∏–æ–Ω–Ω—ã–µ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ –º–æ–≥—É—Ç –±—ã—Ç—å **–±–æ–ª–µ–µ —É—Å—Ç–æ–π—á–∏–≤—ã–º–∏ –∫ —à—É–º—É** –∏ **–ª—É—á—à–µ –ø–∞—Ä–∞–ª–ª–µ–ª–∏–∑—É—é—Ç—Å—è**, –Ω–æ —Ç—Ä–µ–±—É—é—Ç –±–æ–ª—å—à–µ –≤—ã—á–∏—Å–ª–µ–Ω–∏–π.\n",
       "- –í –∑–∞–¥–∞—á–∞—Ö —Å –Ω–µ–ø—Ä–µ—Ä—ã–≤–Ω—ã–º —É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ–º (continuous control) —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–∏–ª—å–Ω–æ –∑–∞–≤–∏—Å—è—Ç –æ—Ç —Å—Ä–µ–¥—ã.\n",
       "- **–ò—Å—Ç–æ—á–Ω–∏–∫:** Zhang, Zaiane ‚Äî *Comparing Deep RL and Evolutionary Methods* (2017).\n",
       "\n",
       "---\n",
       "\n",
       "### –í—ã–≤–æ–¥\n",
       "–ü–æ—Å–ª–µ–¥–Ω–∏–µ –¥–æ—Å—Ç–∏–∂–µ–Ω–∏—è –≤ RL —Å—Ñ–æ–∫—É—Å–∏—Ä–æ–≤–∞–Ω—ã –Ω–∞:\n",
       "- **–ú–∞—Å—à—Ç–∞–±–∏—Ä—É–µ–º–æ—Å—Ç–∏ –∏ –¥–µ—Ü–µ–Ω—Ç—Ä–∞–ª–∏–∑–∞—Ü–∏–∏** (–º–Ω–æ–≥–æ–∞–≥–µ–Ω—Ç–Ω—ã–µ —Å–∏—Å—Ç–µ–º—ã),\n",
       "- **–£—Å—Ç–æ–π—á–∏–≤–æ—Å—Ç–∏ –∏ –æ–±–æ–±—â–µ–Ω–∏–∏** —á–µ—Ä–µ–∑ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–Ω—ã–µ –º–µ—Ç–æ–¥—ã,\n",
       "- **–°—Ä–∞–≤–Ω–µ–Ω–∏–∏ –∏ –≥–∏–±—Ä–∏–¥–∏–∑–∞—Ü–∏–∏** —Ä–∞–∑–ª–∏—á–Ω—ã—Ö –ø–æ–¥—Ö–æ–¥–æ–≤ (RL vs. —ç–≤–æ–ª—é—Ü–∏—è).\n",
       "\n",
       "–•–æ—Ç—è –±–æ–ª—å—à–∏–Ω—Å—Ç–≤–æ —Å—Ç–∞—Ç–µ–π –≤ –ø–æ–∏—Å–∫–µ –¥–∞—Ç–∏—Ä–æ–≤–∞–Ω—ã 2017‚Äì2019 –≥–æ–¥–∞–º–∏, –æ–Ω–∏ –∑–∞–ª–æ–∂–∏–ª–∏ –æ—Å–Ω–æ–≤—É –¥–ª—è —Å–æ–≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –ø—Ä–æ—Ä—ã–≤–æ–≤, —Ç–∞–∫–∏—Ö –∫–∞–∫ **AlphaStar**, **robotic manipulation —Å sparse rewards**, –∏ **offline RL**. –î–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –±–æ–ª–µ–µ —Å–≤–µ–∂–∏—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞—Ö (2023‚Äì2024) –º–æ–∂–Ω–æ —É—Ç–æ—á–Ω–∏—Ç—å –∑–∞–ø—Ä–æ—Å, –Ω–∞–ø—Ä–∏–º–µ—Ä, –ø–æ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–º –º–µ—Ç–æ–¥–∞–º (–Ω–∞–ø—Ä–∏–º–µ—Ä, *offline RL*, *transformer-based RL*, *diffusion policies*)."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "research(\"–†–∞—Å—Å–∫–∞–∂–∏ –ø—Ä–æ –ø–æ—Å–ª–µ–¥–Ω–∏–µ –¥–æ—Å—Ç–∏–∂–µ–Ω–∏—è –≤ –æ–±–ª–∞—Å—Ç–∏ reinforcement learning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "research(\"–ß—Ç–æ –Ω–æ–≤–æ–≥–æ –≤ computer vision –∏ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–∏ –æ–±—ä–µ–∫—Ç–æ–≤?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "research(\"–ù–∞–π–¥–∏ —Å—Ç–∞—Ç—å–∏ –ø—Ä–æ –Ω–µ–π—Ä–æ—Å–µ—Ç–µ–≤–æ–µ —Å–∂–∞—Ç–∏–µ –º–æ–¥–µ–ª–µ–π (model compression)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## –ó–∞–∫–ª—é—á–µ–Ω–∏–µ\n",
    "\n",
    "–í —ç—Ç–æ–º –Ω–æ—É—Ç–±—É–∫–µ –º—ã —Å–æ–∑–¥–∞–ª–∏ **–∞–≥–µ–Ω—Ç–∞-–∏—Å—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—è**, –∫–æ—Ç–æ—Ä—ã–π —É–º–µ–µ—Ç:\n",
    "\n",
    "1. **–ò—Å–∫–∞—Ç—å —Å—Ç–∞—Ç—å–∏** –Ω–∞ arXiv –ø–æ –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–∞–º\n",
    "2. **–ü–æ–ª—É—á–∞—Ç—å –¥–µ—Ç–∞–ª–∏** –æ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã—Ö —Å—Ç–∞—Ç—å—è—Ö\n",
    "3. **–ê–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å** –∏ **—Ä–µ–∑—é–º–∏—Ä–æ–≤–∞—Ç—å** –Ω–∞–π–¥–µ–Ω–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é\n",
    "\n",
    "### –ö–ª—é—á–µ–≤—ã–µ –∫–æ–Ω—Ü–µ–ø—Ü–∏–∏:\n",
    "\n",
    "- **Function Calling** ‚Äî –º–µ—Ö–∞–Ω–∏–∑–º –≤—ã–∑–æ–≤–∞ –≤–Ω–µ—à–Ω–∏—Ö API —á–µ—Ä–µ–∑ LLM\n",
    "- **Pydantic-–º–æ–¥–µ–ª–∏** ‚Äî —É–¥–æ–±–Ω—ã–π —Å–ø–æ—Å–æ–± –æ–ø–∏—Å–∞–Ω–∏—è —Ñ—É–Ω–∫—Ü–∏–π —Å –≤–∞–ª–∏–¥–∞—Ü–∏–µ–π\n",
    "- **–ö–ª–∞—Å—Å Agent** ‚Äî —É–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω–∞—è –æ–±—ë—Ä—Ç–∫–∞ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –≤—ã–∑–æ–≤–æ–≤\n",
    "\n",
    "### –ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–æ–µ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏–µ:\n",
    "\n",
    "- üìö **–õ–∏—Ç–µ—Ä–∞—Ç—É—Ä–Ω—ã–π –æ–±–∑–æ—Ä** ‚Äî –±—ã—Å—Ç—Ä—ã–π –ø–æ–∏—Å–∫ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –ø—É–±–ª–∏–∫–∞—Ü–∏–π\n",
    "- üîç **–ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –æ–±–ª–∞—Å—Ç–∏** ‚Äî –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏–µ –Ω–æ–≤—ã—Ö —Å—Ç–∞—Ç–µ–π –ø–æ —Ç–µ–º–µ\n",
    "- üìù **–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –∫ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—é** ‚Äî –∞–Ω–∞–ª–∏–∑ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö —Ä–∞–±–æ—Ç\n",
    "\n",
    "### –í–æ–∑–º–æ–∂–Ω—ã–µ —É–ª—É—á—à–µ–Ω–∏—è:\n",
    "\n",
    "- –î–æ–±–∞–≤–∏—Ç—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –≤ —Ñ–∞–π–ª\n",
    "- –†–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—é –ø–æ –¥–∞—Ç–µ –ø—É–±–ª–∏–∫–∞—Ü–∏–∏\n",
    "- –î–æ–±–∞–≤–∏—Ç—å —Ñ—É–Ω–∫—Ü–∏—é —Å–∫–∞—á–∏–≤–∞–Ω–∏—è PDF\n",
    "- –°–æ–∑–¥–∞—Ç—å —Ñ—É–Ω–∫—Ü–∏—é —Å—Ä–∞–≤–Ω–µ–Ω–∏—è –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö —Å—Ç–∞—Ç–µ–π"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mas",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
